{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pygad\n",
    "\n",
    "cwd = os.getcwd()\n",
    "pygad_loc = '/grid/home/nbourgeois/codonOpt'\n",
    "os.chdir(pygad_loc)\n",
    "from general_functions import *\n",
    "from metrics import *\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_input = '/grid/home/nbourgeois/data/codon_jason/human PAH codon optimized.fa'\n",
    "# ga_input = '/grid/home/nbourgeois/data/codon_jason/final_seq.fa'\n",
    "output = '' #output filename\n",
    "tissue = 'Liver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cai_on = True\n",
    "bai_on = True\n",
    "cpg_on = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cai_weight_dict = get_codon_weights(tissue)\n",
    "bai_weight_dict = get_bicodon_weights(tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fastaIDs, fastaSeqs) = readFasta(ga_input)\n",
    "aa_seq= str(fastaSeqs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global codon_to_int\n",
    "\n",
    "codon_to_int, gene_space = init_parameters_fun(aa_seq)\n",
    "    \n",
    "gene_space_int = [[codon_to_int[x] for x in y] for y in gene_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastaIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human:\tCAI is 0.912488427575634\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fid,aa_seq in zip(fastaIDs, fastaSeqs):\n",
    "    cai = get_cai(aa_seq, cai_weight_dict)\n",
    "\n",
    "    print(\"{}:\\tCAI is {}\".format(fid,cai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1939985177.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_39284/1939985177.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for aa_seq,id in fastaIDs fastaSeqs:\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for aa_seq,id in fastaIDs fastaSeqs:\n",
    "    bai = get_bai(aa_seq, bai_weight_dict)\n",
    "    print(\"{}:\\tBAI is {}\".format(id,bai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpg\n",
    "for aa_seq,id in fastaIDs fastaSeqs:\n",
    "    bai = get_cpg(aa_seq, bai_weight_dict)\n",
    "    print(\"{}:\\tcpg is {}\".format(id,bai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfasdfasdfasd 2cawsdcwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sols = {}\n",
    "\n",
    "global total_weight\n",
    "total_weight = sum([cai_w,bai_w,sps_w,cpg_w,pas_w])\n",
    "tissue = 'Liver'\n",
    "cai_index_loc = os.path.join(pygad_loc,'CoCoPUTs_codon_usage/codon_usage/'+tissue+'.codon.txt')\n",
    "bai_index_loc = os.path.join(pygad_loc,'CoCoPUTs_codon_usage/bicodon_usage/'+tissue+'.bicodon.txt')\n",
    "\n",
    "codon_usage_table_loc = os.path.join(pygad_loc,'codon_usage.getex.txt')\n",
    "\n",
    "def fitness_func(solution, solution_idx):\n",
    "    \n",
    "    if not type(solution) is str:\n",
    "        seq_aa = ''.join([codon_to_int[x] for x in solution])\n",
    "    else:\n",
    "        seq_aa = solution\n",
    "#     print(solution_idx)\n",
    "\n",
    "    tmp_dict = {}\n",
    "    \n",
    "    #Check for redundancy\n",
    "#     if seq_aa in all_sols.keys():\n",
    "#         fitness = all_sols[seq_aa]['fitness']\n",
    "\n",
    "#     else:\n",
    "    fitness = 0\n",
    "\n",
    "    if cai_on:\n",
    "        cai = get_cai(seq_aa, cai_index_loc)\n",
    "        fitness += cai*cai_w\n",
    "        tmp_dict['cai'] = cai\n",
    "\n",
    "    if bai_on:\n",
    "        bai = get_bai(seq_aa, bai_index_loc)\n",
    "        fitness += bai*bai_w\n",
    "        tmp_dict['bai'] = bai\n",
    "\n",
    "    if cpg_on:\n",
    "        cpg = get_cpg(seq_aa)\n",
    "        fitness += cpg*cpg_w\n",
    "        tmp_dict['cpg'] = cpg\n",
    "\n",
    "    if sps_on:\n",
    "        sps = get_sps(seq_aa)\n",
    "        print('SPS retuned.')\n",
    "\n",
    "        fitness += sps*sps_w\n",
    "        tmp_dict['sps'] = sps\n",
    "\n",
    "    if pas_on:\n",
    "        pas = get_pas(seq_aa)\n",
    "        fitness += pas*pas_w\n",
    "        tmp_dict['pas'] = pas\n",
    "\n",
    "    fitness = fitness/total_weight\n",
    "    tmp_dict['fitness'] = fitness\n",
    "    all_sols[seq_aa] = tmp_dict\n",
    "        \n",
    "    \n",
    "    return tmp_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdir = '/data/JiraAnalyses/Misc/MISC-17'\n",
    "# os.chdir(cdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fas = glob.glob( '*1k.fa')\n",
    "# fas.append('Translated_Region_PAH.fa')                \n",
    "# fas.append('PAH_codon_random.fa')                \n",
    "# # fas =['Translated_Region_PAH.fa'  ]             \n",
    "# fas = fas[0:2]\n",
    "# fas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/data/JiraAnalyses/Misc/MISC-17')\n",
    "# fastaIds = []\n",
    "# fastaSeqs = []\n",
    "# for file in fas:\n",
    "#     print(file)\n",
    "#     (fastaIds_t, fastaSeqs_t) = readFasta( file )\n",
    "#     fastaIds.extend(fastaIds_t)\n",
    "#     fastaSeqs.extend(fastaSeqs_t)\n",
    "    \n",
    "# opts = [x.split('_')[0] for x in fastaIds]\n",
    "# fastaSeqs = [str(x) for x in fastaSeqs]\n",
    "# all_seqs = pd.DataFrame(data = {'Type': opts, 'Seq': fastaSeqs,'SeqID':fastaIds})\n",
    "# all_seqs = all_seqs.set_index('SeqID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSites_multi( fastaIds,fastaSeqs,threshold=.1):\n",
    "\n",
    "    gpu0_avail = gpu_memory_usage(0)\n",
    "    gpu1_avail = gpu_memory_usage(1)\n",
    "    if gpu0_avail + gpu1_avail > 30000:\n",
    "        print('Out of memory\\n')\n",
    "        return(-1)\n",
    "    if gpu0_avail < gpu1_avail:\n",
    "        gpu=\"0\"\n",
    "    else:\n",
    "        gpu=\"1\"\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu\n",
    "\n",
    "    from keras.models import load_model\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "\n",
    "    results = {}\n",
    "    gpus =tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "    try: \n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "        \n",
    "        context = 10000\n",
    "        keras.backend.set_learning_phase(0)\n",
    "        paths = ('models/spliceai{}.h5'.format(x) for x in range(1, 6))\n",
    "        models = [load_model(resource_filename('spliceai', x), compile=False ) for x in paths]\n",
    "        for seq_id, seq in zip(fastaIds,fastaSeqs):\n",
    "\n",
    "            x = one_hot_encode('N'*(context//2) + str(seq) + 'N'*(context//2))[None, :]\n",
    "            y = np.mean([models[m].predict(x) for m in range(5)], axis=0)\n",
    "            acceptor_prob = y[0, :, 1]\n",
    "            donor_prob = y[0, :, 2]\n",
    "            coord = list( range(1, len( donor_prob ) ) )\n",
    "                    \n",
    "            # custom metric\n",
    "            results[seq_id] = (len(acceptor_prob[acceptor_prob > threshold]) + len(donor_prob[donor_prob > .1]))/2\n",
    "            results[seq_id] = (acceptor_prob[acceptor_prob > threshold],donor_prob[donor_prob > .1])\n",
    "        return(results)\n",
    "    except tf.errors as e:\n",
    "        # Splice AI custome sequeence prediction\n",
    "        print(e,'\\n')\n",
    "        return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 11:11:57.926179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-19 11:11:57.997056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:d7:00.0\n",
      "2022-01-19 11:11:58.028643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-01-19 11:11:58.997434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-01-19 11:11:59.298585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-01-19 11:11:59.460730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-01-19 11:12:00.452527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-01-19 11:12:01.212801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-01-19 11:12:02.911173: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 11:12:02.920154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2022-01-19 11:12:03.509421: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2022-01-19 11:12:03.859073: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000000000 Hz\n",
      "2022-01-19 11:12:03.879733: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564217d20fc0 executing computations on platform Host. Devices:\n",
      "2022-01-19 11:12:03.879762: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-19 11:12:03.890550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:d7:00.0\n",
      "2022-01-19 11:12:03.890608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-01-19 11:12:03.890623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-01-19 11:12:03.890638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-01-19 11:12:03.890651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-01-19 11:12:03.890664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-01-19 11:12:03.890677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-01-19 11:12:03.890690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 11:12:03.891215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2022-01-19 11:12:03.891362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-01-19 11:12:04.044767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-19 11:12:04.044805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2022-01-19 11:12:04.044900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2022-01-19 11:12:04.046070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5000 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:d7:00.0, compute capability: 7.0)\n",
      "2022-01-19 11:12:04.066597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564218680e10 executing computations on platform CUDA. Devices:\n",
      "2022-01-19 11:12:04.066620: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2022-01-19 11:12:28.221938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 11:12:31.725885: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 3.02 s, total: 24.6 s\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sps_results = predictSites_multi(fastaIDs,fastaSeqs,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.11014947, 0.1761796 ], dtype=float32),\n",
       " array([0.32031715], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps_results['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def ps_wrapper(fastaIds,fastaSeqs,threshold,q):\n",
    "    print('a')\n",
    "    results = predictSites_multi(fastaIds,fastaSeqs,threshold)\n",
    "    print('a')\n",
    "\n",
    "#     q.put(results)\n",
    "    print('a')\n",
    "\n",
    "    return None\n",
    "\n",
    "q = multiprocessing.Queue()  #store the result\n",
    "pro1 = multiprocessing.Process(target=ps_wrapper, args=(fastaIds,fastaSeqs,.1,q))\n",
    "\n",
    "pro1.start()\n",
    "pro1.join()\n",
    "# results = q.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def ps_wrapper(fastaIds,fastaSeqs,threshold,q):\n",
    "    print('a')\n",
    "    results = predictSites_multi(fastaIds,fastaSeqs,threshold)\n",
    "    print('a')\n",
    "\n",
    "    L.append(\"anything\")\n",
    "\n",
    "    print('a')\n",
    "\n",
    "    return None\n",
    "\n",
    "def dothing(L, i):  # the managed list `L` passed explicitly.\n",
    "\n",
    "with Manager() as manager:\n",
    "    L = manager.list()  # <-- can be shared between processes.\n",
    "    p = Process(target=ps_wrapper, args=(fastaIds,fastaSeqs,.1,L))  # Passing the list\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "    p.join()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# poly-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdir = os.getcwd()\n",
    "# script_dir = os.path.join(pygad_loc,'DeepPASTA_gpu')\n",
    "# os.chdir(script_dir)\n",
    "# shutil.rmtree('./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_fasta(fID,seq):\n",
    "#     header = '>' + fID\n",
    "#     return('\\n'.join([header,seq,'']))\n",
    "\n",
    "# os.mkdir('tmp')\n",
    "# files = []\n",
    "# size=500\n",
    "# k=0\n",
    "# n=0\n",
    "# i=0\n",
    "# while i < len(fastaIds):\n",
    "#     infile = './tmp/tmp{}.fa'.format(k)\n",
    "#     filestr = ''\n",
    "#     for j in range(size):\n",
    "#         if i >= len(fastaIds):\n",
    "#             break\n",
    "#         fID = fastaIds[i]\n",
    "#         seq = fastaSeqs[i]\n",
    "#         filestr = filestr + add_fasta(fID,seq)\n",
    "#         files.append(infile)\n",
    "#         i+=1\n",
    "#         n+=1\n",
    "#     with open(infile,'w') as fileo:\n",
    "#         fileo.write(filestr)       \n",
    "       \n",
    "\n",
    "#     k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def launch_deepPASTA(num):\n",
    "#     num = str(num)\n",
    "#     infile = './tmp/tmp{}.fa'.format(num)\n",
    "#     out_pre='./tmp/tmp{}'.format(num)\n",
    "#     cmd = 'nice sh ./deep_pasta.sh {infile} {out_pre}'.format(infile=infile, out_pre=out_pre)\n",
    "#     print(cmd)\n",
    "#     cmd = cmd.split(' ')\n",
    "#     process=sp.Popen(cmd)\n",
    "#     result = process.communicate()\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing \n",
    "# numOfFiles = int(np.ceil((len(fastaIds))/size))\n",
    "# pool = multiprocessing.Pool(numOfFiles)\n",
    "# outs = pool.map(launch_deepPASTA, range(numOfFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max\n",
    "original_max=0\n",
    "for key in sps_results.keys():\n",
    "    opt = key.split('_')[0]\n",
    "    if opt == 'Original':\n",
    "        if original_max < sps_results[key]:\n",
    "            original_max = sps_results[key]\n",
    "# filter\n",
    "limit = original_max +.5\n",
    "print(limit)\n",
    "filt_fastaIds = []\n",
    "for key in sps_results.keys():\n",
    "    opt = key.split('_')[0]\n",
    "    if opt == 'RandomSeq':\n",
    "        continue\n",
    "    if sps_results[key] <= limit:\n",
    "        filt_fastaIds.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_seqs = all_seqs.loc[filt_fastaIds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random' in 'SeqID:RandomSeq_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poor SPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max\n",
    "original_min=0\n",
    "for key in sps_results.keys():\n",
    "    opt = key.split('_')[0]\n",
    "    if original_min < sps_results[key]:\n",
    "        original_min = sps_results[key]\n",
    "# filter\n",
    "limit = original_min -.5\n",
    "filt_fastaIds_poor = []\n",
    "for key in sps_results.keys():\n",
    "    opt = key.split('_')[0]\n",
    "    if sps_results[key] >= limit:\n",
    "        filt_fastaIds_poor.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_seqs_poor = all_seqs.loc[filt_fastaIds_poor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_seqs_poor['Type'] = 'PoorSplicing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_HammingDistance(X):\n",
    "    return (X[:, None, :] != X).sum(2)\n",
    "\n",
    "def check_sol(i,j,k):\n",
    "    ij_d = distMat[i,j]\n",
    "    ik_d = distMat[i,k]\n",
    "    jk_d = distMat[j,k]\n",
    "    return(ij_d + ik_d + jk_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sols = {}\n",
    "# for seq_type in filt_seqs['Type'].unique():\n",
    "for seq_type in ['cpg-n']:\n",
    "    if seq_type == 'Original':\n",
    "        continue\n",
    "    print(seq_type)\n",
    "    filt_seqs_sub = filt_seqs.loc[filt_seqs['Type']==seq_type]\n",
    "    top_seqs = np.array([np.array(list(seq)) for seq in filt_seqs_sub['Seq']])\n",
    "    #distance_matrix\n",
    "    distMat = compute_HammingDistance(top_seqs)\n",
    "\n",
    "    max_dist = 0\n",
    "    for i in range(len(distMat)-2):\n",
    "        j=i+1\n",
    "        while (j < (len(distMat)-1)):\n",
    "            k=j+1\n",
    "            while (k < len(distMat)):\n",
    "                if check_sol(i,j,k) > max_dist:\n",
    "                    sol = (i,j,k)\n",
    "                    max_dist = check_sol(i,j,k)\n",
    "                k+=1\n",
    "            j+=1\n",
    "    sols[seq_type] = filt_seqs_sub.iloc[list(sol)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sols['RandomSeq'] = all_seqs.loc[all_seqs['Type']=='RandomSeq'][0:3]\n",
    "sols['PoorSplicing'] = filt_seqs_poor\n",
    "sols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ''\n",
    "for key in sols:\n",
    "    df = sols[key]\n",
    "    for row in df.iterrows():\n",
    "        index = row[0]\n",
    "        seq = row[1]['Seq']\n",
    "        fa_header = \">:{0}\\n\".format(index)\n",
    "        file = file + fa_header + seq + '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.join(pygad_loc,'DeepPASTA_gpu')\n",
    "os.chdir(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_seq_prePAS.fa','w') as fileo:\n",
    "    fileo.write('>original\\n{}\\n'.format(aa_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = 'final_seq_prePAS.fa'\n",
    "out_pre= 'final_seq_prePAS'\n",
    "cmd = 'nice sh ./deep_pasta.sh {infile} {out_pre}'.format(infile=infile, out_pre=out_pre)\n",
    "print(cmd)\n",
    "cmd = cmd.split(' ')\n",
    "process=sp.Popen(cmd)\n",
    "result = process.communicate()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pas = pd.read_csv('final_seq_prePAS.report.txt',sep='\\t',header=None)\n",
    "df_pas\n",
    "df_pas[2] = df_pas[0].str.split(':',expand=True)[0]\n",
    "pas_results = df_pas.groupby(2)[1].max().to_dict()\n",
    "pas_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pas = pd.read_csv('final_seq_prePAS.report.txt',sep='\\t',header=None)\n",
    "df_pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_ids = []\n",
    "bais = []\n",
    "cais = []\n",
    "cpgs = []\n",
    "spss = []\n",
    "passs = []\n",
    "fitnesses = []\n",
    "\n",
    "for key in sols:\n",
    "    df = sols[key]\n",
    "    i=0\n",
    "    for row in df.iterrows():\n",
    "        index = row[0]\n",
    "        rtype = row[1]['Type']\n",
    "        seq = row[1]['Seq']\n",
    "        seq_id = rtype+'_'+str(i)\n",
    "    #     dist_others = sum(distMat[sol,:].T[sol,:][i]) #\n",
    "        fit_dict = fitness_func(seq,0)\n",
    "        cai = fit_dict['cai']\n",
    "        bai = fit_dict['bai']\n",
    "        cpg = fit_dict['cpg']\n",
    "        sps = sps_results[index]\n",
    "        pas = pas_results[index]\n",
    "    #     pas = fit_dict['pas']\n",
    "        fitness = fit_dict['fitness']\n",
    "\n",
    "        fa_header = \">SeqID:{0}_CAI:{1}_BAI:{2}_CpG:{3}_SPS:{4}_\".format(seq_id, cai, bai, cpg, sps) + \\\n",
    "                \"PAS:{0}_Fitness:{1}\\n\".format(pas, fitness)\n",
    "#         fa_header = \">SeqID:{0}\\n\".format(seq_id)\n",
    "        i+=1\n",
    "        print(fa_header)\n",
    "        file = file + fa_header + seq + '\\n'\n",
    "        seq_ids.append(seq_id) \n",
    "        bais.append(bai)\n",
    "        cais.append(cai)\n",
    "        cpgs.append(cpg)\n",
    "        spss.append(sps)\n",
    "        passs.append(pas)\n",
    "        fitnesses.append(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame(data={'SeqID':seq_ids,'CAI':cais,'BAI':bais,'CpG':cpgs,'SPS':spss,'PAS':passs,'Fitness':fitnesses})\n",
    "all_df = all_df.set_index('SeqID')\n",
    "all_df.to_csv('meta_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cdir)\n",
    "with open('final_seq.fa','w') as fileo:\n",
    "    fileo.write(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (GPU)",
   "language": "python",
   "name": "bfx-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
